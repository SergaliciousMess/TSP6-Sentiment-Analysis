'''
    @author SergaliciousMess
    @author emyasenc
    
    Description: an edited verison of primary Python file for the sentiment analysis class, originally commited from @author SergaliciousMess
                 Note: The following are further tasks to take into consideration for the CNN model for this class:
                 
                Neutral Sentiment: Define a clear criterion for neutral sentiment. It's a subjective decision and may require additional analysis of the dataset (when we acquire the labeled data).
                Evaluation Metrics: Consider implementing evaluation metrics such as accuracy, precision, recall, and F1-score to assess model performance during training and testing.
                Hyperparameter Tuning: Experiment with different hyperparameters such as learning rate, batch size, and model architecture to improve model performance.
                Error Handling: Implement error handling mechanisms to gracefully handle exceptions and errors during data processing and model training.
                
                
Downlaod spacy to your device before running:                
To use spacy in Python code, install the library using pip:
pip install spacy

Also need to download language models for the languages one intends to process. For example, download the English language model using the following command:
python -m spacy download en_core_web_sm
   '''

import torch
import spacy
import numpy as np
from torch import nn
from torch.utils.data import DataLoader
from torchtext.data.utils import get_tokenizer
from torchtext.vocab import build_vocab_from_iterator
from torchtext.datasets import AG_NEWS # data placeholder, TODO: to be deleted or replaced later as seen fit
from torchtext.data.functional import to_map_style_dataset

#device- desired device for computations
#data_type- desired number format
#optimizer- lambda function for desired pytorch optimization algorithm
#learning_rate- desired learning rate for optimization
#loss_function- lambda function for desired pytorch loss calculation algorithm

class SentimentAnalysis():
    def __init__(self, 
                 device="cuda:0" if torch.cuda.is_available() else "cpu",
                 data_type=torch.float32,
                 optimizer=torch.optim.Adam,
                 nlp = spacy.load("en_core_web_sm"),
                 learning_rate=0.001, # corrected learning curve value
                 loss_function=torch.nn.CrossEntropyLoss()):
        
        # Set device and data type defaults
        torch.set_default_device(device)
        torch.set_default_dtype(data_type)
        
        # Define the nn architecture
        self.model = nn.Sequential(
            nn.Linear(64, 1),  # FIXME this is a placeholder constructor for the linear part of the neural network; Linear layer with input size 64 and output size 1
            nn.Sigmoid()       # Sigmoid activation function for binary classification
        )
        
        # Initialize optimizer and loss function
        self.optimizer = optimizer(self.model.parameters(), lr=learning_rate)
        self.loss_function = loss_function

    def tokenize(self, text):
        # Use spaCy for advanced tokenization
        doc = self.nlp(text)
        
        # Extract tokens after applying additional processing
        tokens = [token.lemma_.lower().strip() for token in doc if not token.is_stop and not token.is_punct]
        
        return tokens

    def build_vocab(self, data):
        # Build vocabulary from the tokenized data
        vocab = build_vocab_from_iterator(map(self.tokenize, data), specials=["<unk>"])
        vocab.set_default_index(vocab["<unk>"])
        return vocab
    
    def text_to_numerical(self, text):
        # Convert tokenized text to numerical representation using vocabulary
        numerical_representation = [self.vocab[token] for token in self.tokenize(text)]
        return numerical_representation

    # Returns sentiment_labels
    def analyze(self, input_text: str):
       # Convert input_text to numerical representation using vocabulary
       # Represents text data before feeding it into the model. 
       # Convert text data into numerical representations (e.g., word embeddings) using NumPy arrays.
        numerical_representation = self.text_to_numerical(input_text)
        
        # Convert numerical representation to NumPy array  
        input_array = np.array(numerical_representation)
        
        # Convert input_tokens to tensor
        input_tensor = torch.tensor(input_array)  
        
        # Forward pass through the model
        output = self.model(input_tensor)
        
        # Performing any post-processing to convert output probabilities to sentiment labels
        
        # Output is a tensor of probabilities 
        # Define the threshold values for each sentiment category
        positive_threshold = 0.7 # This can be changed as necessary later
        negative_threshold = 0.3 # So can this one
        
        # Convert probabilities to sentiment labels
        sentiment_labels = []
        for probability in output:
            if probability >= positive_threshold:
                sentiment_labels.append("Positive")
            elif probability <= negative_threshold:
                sentiment_labels.append("Negative")
            else:
                sentiment_labels.append("Neutral")
        
        return sentiment_labels
    
    def train(self, train_iter, val_iter, epochs=10):
        # Define the training loop
        for epoch in range(epochs):
            running_loss = 0.0 # Initial running loss is 0.0
            for idx, (inputs, labels) in enumerate(train_iter):
                # Zero the parameter gradients
                self.optimizer.zero_grad()

                # Forward pass
                outputs = self.model(inputs)
                
                # Compute the loss
                loss = self.loss_function(outputs, labels)
                
                # Backward pass and optimization
                loss.backward()
                self.optimizer.step()

                # Print statistics
                running_loss += loss.item()
            print(f"Epoch {epoch+1}, Loss: {running_loss}")
        
if __name__ == "__main__":
    # Load AG_NEWS dataset; TODO: can be changed or replaced later with new dataset
    train_iter = AG_NEWS(split='train')
    test_iter = AG_NEWS(split='test')

    # Initialize SentimentAnalysis object
    sentiment_analysis = SentimentAnalysis()

    # Tokenize and build vocabulary
    sentiment_analysis.build_vocab(train_iter)

    # Convert data iterators to map-style datasets
    train_dataset = to_map_style_dataset(train_iter)
    test_dataset = to_map_style_dataset(test_iter)

    # Create DataLoader for training and testing
    train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)

    # Train the model
    sentiment_analysis.train(train_dataloader, test_dataloader, epochs=10)